{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a short tutorial on how to access weights in a network, copy and write values directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take the network that was defined in the pytorch tutorial and generate a random classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleNet()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1.)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "##Â Generating just a single example of data and target\n",
    "data = torch.randn(1, 1, 32, 32)\n",
    "target = torch.randint(0, 10, (1,))\n",
    "\n",
    "### doing three epochs of optimization\n",
    "for _ in range(3):\n",
    "    out = model(data)\n",
    "    loss = criterion(out, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's have a look at the weights. Weights can be accessed by using the name of the layer, and the weights property. For example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0190, -0.0214,  0.0443,  ..., -0.0270,  0.0069, -0.0229],\n",
       "        [ 0.0389,  0.0178,  0.0239,  ..., -0.0206,  0.0092, -0.0302],\n",
       "        [ 0.0309, -0.0155,  0.0243,  ..., -0.0073, -0.0308, -0.0098],\n",
       "        ...,\n",
       "        [ 0.0239, -0.0097, -0.0216,  ..., -0.0380,  0.0001, -0.0399],\n",
       "        [-0.0241,  0.0358, -0.0399,  ...,  0.0054, -0.0128,  0.0218],\n",
       "        [-0.0267, -0.0023,  0.0251,  ...,  0.0267,  0.0235,  0.0068]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc1.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access just the tensor data by doing :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0190, -0.0214,  0.0443,  ..., -0.0270,  0.0069, -0.0229],\n",
       "        [ 0.0389,  0.0178,  0.0239,  ..., -0.0206,  0.0092, -0.0302],\n",
       "        [ 0.0309, -0.0155,  0.0243,  ..., -0.0073, -0.0308, -0.0098],\n",
       "        ...,\n",
       "        [ 0.0239, -0.0097, -0.0216,  ..., -0.0380,  0.0001, -0.0399],\n",
       "        [-0.0241,  0.0358, -0.0399,  ...,  0.0054, -0.0128,  0.0218],\n",
       "        [-0.0267, -0.0023,  0.0251,  ...,  0.0267,  0.0235,  0.0068]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc1.weight.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to copy these values into another place (e.g. to store the full precision version of the weights), use the clone function followed by a copy_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0190, -0.0214,  0.0443,  ..., -0.0270,  0.0069, -0.0229],\n",
       "        [ 0.0389,  0.0178,  0.0239,  ..., -0.0206,  0.0092, -0.0302],\n",
       "        [ 0.0309, -0.0155,  0.0243,  ..., -0.0073, -0.0308, -0.0098],\n",
       "        ...,\n",
       "        [ 0.0239, -0.0097, -0.0216,  ..., -0.0380,  0.0001, -0.0399],\n",
       "        [-0.0241,  0.0358, -0.0399,  ...,  0.0054, -0.0128,  0.0218],\n",
       "        [-0.0267, -0.0023,  0.0251,  ...,  0.0267,  0.0235,  0.0068]],\n",
       "       grad_fn=<CopyBackwards>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_fc1_initialvalue = model.fc1.weight.clone()\n",
    "weights_fc1_initialvalue.copy_(model.fc1.weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's say you want to modify all the values of the weight by hand, for instance let's replace those weights by their absolute value. This can be done by : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0190, 0.0214, 0.0443,  ..., 0.0270, 0.0069, 0.0229],\n",
       "        [0.0389, 0.0178, 0.0239,  ..., 0.0206, 0.0092, 0.0302],\n",
       "        [0.0309, 0.0155, 0.0243,  ..., 0.0073, 0.0308, 0.0098],\n",
       "        ...,\n",
       "        [0.0239, 0.0097, 0.0216,  ..., 0.0380, 0.0001, 0.0399],\n",
       "        [0.0241, 0.0358, 0.0399,  ..., 0.0054, 0.0128, 0.0218],\n",
       "        [0.0267, 0.0023, 0.0251,  ..., 0.0267, 0.0235, 0.0068]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc1.weight.data.copy_(torch.abs(model.fc1.weight.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that the weights have been modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0190, 0.0214, 0.0443,  ..., 0.0270, 0.0069, 0.0229],\n",
       "        [0.0389, 0.0178, 0.0239,  ..., 0.0206, 0.0092, 0.0302],\n",
       "        [0.0309, 0.0155, 0.0243,  ..., 0.0073, 0.0308, 0.0098],\n",
       "        ...,\n",
       "        [0.0239, 0.0097, 0.0216,  ..., 0.0380, 0.0001, 0.0399],\n",
       "        [0.0241, 0.0358, 0.0399,  ..., 0.0054, 0.0128, 0.0218],\n",
       "        [0.0267, 0.0023, 0.0251,  ..., 0.0267, 0.0235, 0.0068]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc1.weight.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we would like to restore the previous values of the weights. Fortunately we have saved them previously. So we just have to do : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0190, -0.0214,  0.0443,  ..., -0.0270,  0.0069, -0.0229],\n",
       "        [ 0.0389,  0.0178,  0.0239,  ..., -0.0206,  0.0092, -0.0302],\n",
       "        [ 0.0309, -0.0155,  0.0243,  ..., -0.0073, -0.0308, -0.0098],\n",
       "        ...,\n",
       "        [ 0.0239, -0.0097, -0.0216,  ..., -0.0380,  0.0001, -0.0399],\n",
       "        [-0.0241,  0.0358, -0.0399,  ...,  0.0054, -0.0128,  0.0218],\n",
       "        [-0.0267, -0.0023,  0.0251,  ...,  0.0267,  0.0235,  0.0068]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc1.weight.data.copy_(weights_fc1_initialvalue.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('base': conda)",
   "language": "python",
   "name": "python36964bitbaseconda6c8d87063a18461ca77c51084a3826c5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
